{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/causal-discovery-dv')\n",
    "\n",
    "from cdrl.agent.mcts.mcts_agent import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "import seaborn as sns\n",
    "\n",
    "from cdrl.io.storage import EvaluationStorage\n",
    "from cdrl.io.file_paths import FilePaths\n",
    "\n",
    "discrete_instances = [\"asia\", \"child\", \"insurance\"]\n",
    "fp_out = FilePaths('/experiment_data', 'aggregate_cdrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T09:39:55.156853Z",
     "start_time": "2024-02-09T09:39:55.145815Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "metrics_to_display = {\n",
    "    \"construct\": [\"shd\", \"fdr\", \"tpr\", \"reward\"],\n",
    "}\n",
    "\n",
    "def get_eval_df(experiment_ids, which_results=\"construct\", collapse_syntren=True, skip_nonmdp=True):\n",
    "    all_eval_data = []\n",
    "\n",
    "    for exp_id in experiment_ids:\n",
    "        fp_in = FilePaths('/experiment_data', exp_id)\n",
    "        storage = EvaluationStorage(fp_in)\n",
    "\n",
    "        emd = storage.get_metrics_data(\"eval\")\n",
    "\n",
    "        metrics = metrics_to_display[which_results]\n",
    "\n",
    "        for entry in emd:\n",
    "            if which_results == \"construct\":\n",
    "                if skip_nonmdp and entry[\"agent\"] in [\"cam\", \"lingam\", \"notears\"]:\n",
    "                    continue\n",
    "\n",
    "            for metric in metrics:\n",
    "                row_dict = {}\n",
    "\n",
    "                row_dict[\"metric\"] = metric\n",
    "                row_dict[\"value\"] = entry[\"results\"][which_results][metric]\n",
    "\n",
    "                row_dict[\"agent\"] = entry[\"agent\"]\n",
    "                if entry[\"agent\"].startswith(\"uct\"):\n",
    "                    row_dict[\"agent\"] = \"uct\"\n",
    "\n",
    "                # if entry[\"agent\"] not in [\"cam\", \"lingam\", \"notears\"]:\n",
    "                #     row_dict[\"agent\"] = row_dict[\"agent\"] + \"_\" + exp_id[-7:]\n",
    "\n",
    "                row_dict[\"instance\"] = exp_id.split(\"_\")[0]\n",
    "\n",
    "                if collapse_syntren:\n",
    "                    if row_dict[\"instance\"].startswith(\"syntren\"):\n",
    "                        row_dict[\"instance\"] = \"syntren\"\n",
    "\n",
    "                all_eval_data.append(row_dict)\n",
    "\n",
    "    eval_df = pd.DataFrame(all_eval_data)\n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "def compute_ci(data, confidence=0.95):\n",
    "    if len(data) == 1:\n",
    "        return 0.\n",
    "\n",
    "    a = np.array(data)\n",
    "    n = len(a)\n",
    "    se = sp.stats.sem(a)\n",
    "    h = se * sp.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h\n",
    "\n",
    "def augment_with_cis(results_pivot, orig_df):\n",
    "    pivot_cp = deepcopy(results_pivot)\n",
    "\n",
    "    all_algos = results_pivot.columns.tolist()[2:]\n",
    "    all_algos = [a for a in all_algos if a not in [\"greedy\", \"cam\", \"notears\", \"lingam\", \"gobnilp\"]]\n",
    "\n",
    "    for algo in all_algos:\n",
    "        algo_cis = []\n",
    "\n",
    "        for row in results_pivot.itertuples():\n",
    "            metric = getattr(row, 'metric')\n",
    "            instance = getattr(row, \"instance\")\n",
    "\n",
    "            # print(algo, metric, instance)\n",
    "            relevant_entries = orig_df[(orig_df[\"metric\"] == metric) &\n",
    "                                       (orig_df['instance'] == instance) &\n",
    "                                       (orig_df['agent'] == algo)]\n",
    "            metric_values = relevant_entries[\"value\"].tolist()\n",
    "            ci = compute_ci(metric_values)\n",
    "            # print(metric_values, ci)\n",
    "            algo_cis.append(ci)\n",
    "\n",
    "        pivot_cp[f\"{algo}_ci\"] = algo_cis\n",
    "\n",
    "    for algo in all_algos:\n",
    "        colname_ci = f\"{algo}_ci\"\n",
    "        pivot_cp[algo] = pivot_cp.agg(lambda x: f\"{x[algo]:.3f}±{x[colname_ci]:.3f}\", axis=1)\n",
    "        pivot_cp.drop(columns=[colname_ci], inplace=True)\n",
    "\n",
    "    return pivot_cp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T09:40:04.699780Z",
     "start_time": "2024-02-09T09:40:04.663463Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def prepare_and_write_latex(df, which_results=\"construct\", file_suffix=\"\"):\n",
    "    colorder = [\"instance\", \"metric\", \"uct\", \"greedy\", \"randomshooting\", \"random\", \"gobnilp\"]\n",
    "\n",
    "    print(colorder)\n",
    "    agent_display_names = {\"uct\": \"CD-UCT\",\n",
    "                           \"rlbic\": \"RL-BIC\",\n",
    "                           \"greedy\": \"Greedy Search\",\n",
    "                           \"random\": \"Random Sampling\",\n",
    "                           \"randomshooting\": \"Random Search\",\n",
    "                           \"cam\": \"CAM\",\n",
    "                           \"lingam\": \"LiNGAM\",\n",
    "                           \"notears\": \"NOTEARS\",\n",
    "                           \"gobnilp\": \"GOBNILP\"}\n",
    "\n",
    "    df = df[colorder]\n",
    "    df['metric'] = pd.Categorical(df['metric'],categories=['reward', 'tpr','fdr','shd'], ordered=True)\n",
    "    \n",
    "    if file_suffix == \"discrete\":\n",
    "        df[\"instance\"] = pd.Categorical(df['instance'], categories=discrete_instances, ordered=True)\n",
    "\n",
    "    if which_results == \"joint\":\n",
    "        df = df.sort_values(by=[\"phase\", \"instance\", \"metric\"])\n",
    "    elif file_suffix == \"discrete\":\n",
    "        df = df.sort_values(by=[\"instance\", \"metric\"])\n",
    "    elif file_suffix == \"\":\n",
    "        df = df.sort_values(by=[\"instance\", \"metric\"])\n",
    "    else:\n",
    "        df = df.sort_values(by=[\"metric\"])\n",
    "\n",
    "    if which_results == \"prune_cam\":\n",
    "        df.loc[ df[\"instance\"] == \"syntren\", [\"notears\"]] = -100\n",
    "    df.rename(columns=agent_display_names, inplace=True)\n",
    "\n",
    "    texfile =  str(fp_out.figures_dir / f\"{which_results}_final{'_' + file_suffix if file_suffix != '' else ''}.tex\")\n",
    "    fh = open(texfile, 'w')\n",
    "\n",
    "    n_startcols = 3 if which_results == \"joint\" else (2 if file_suffix == \"\" else 1)\n",
    "\n",
    "    colformat = f\"{'c' * n_startcols}|\" + (\"r\" * (len(colorder) - n_startcols))\n",
    "    df.to_latex(buf=fh, float_format=\"{:0.3f}\".format, index=False, column_format=colformat)\n",
    "    fh.close()\n",
    "\n",
    "    replace_dict = {}\n",
    "    if file_suffix == \"discrete\":\n",
    "        replace_dict[r\"nan±nan\"] =  r\"?\"\n",
    "    else:\n",
    "        replace_dict[r\"nan±nan\"] =  r\"$\\\\infty$\"\n",
    "        \n",
    "    replace_dict.update({\n",
    "        r\"instance\" : r\"\",\n",
    "        r\"agg\" : r\"\",\n",
    "        r\"metric\" : r\"\",\n",
    "        r\"phase\": r\"Phase\",\n",
    "        r\"construct\": r\"\\\\textbf{Construct}\",\n",
    "        r\"prune\": r\"\\\\textbf{Prune}\",\n",
    "\n",
    "        r\"reward\": r\"Reward $\\\\uparrow$\",\n",
    "        r\"tpr\": r\"TPR $\\\\uparrow$\",\n",
    "        r\"fdr\": r\"FDR $\\\\downarrow$\",\n",
    "        r\"shd\": r\"SHD $\\\\downarrow$\",\n",
    "        r\"-100.000\": r\"$\\\\times$\",\n",
    "        r\"-999.000\": r\"---\",\n",
    "\n",
    "        r\"sachs\": r\"\\\\textit{Sachs}\",\n",
    "        r\"syntren\": r\"\\\\textit{SynTReN}\",\n",
    "        \n",
    "        r\"asia\": r\"\\\\textit{Asia}\",\n",
    "        r\"child\": r\"\\\\textit{Child}\",\n",
    "        r\"insurance\": r\"\\\\textit{Insurance}\",\n",
    "        \n",
    "        r\"mrr\": r\"MRR\",\n",
    "\n",
    "        r\"NaN\": r\"$\\\\infty$\",\n",
    "        r\"nan\": r\"$\\\\infty$\",\n",
    "\n",
    "        r\"±(\\d+\\.\\d+)\": r\"\\\\tiny{$\\\\pm\\g<1>$}\",\n",
    "        r\"±---\": r\"\\\\tiny{$\\\\pm0.000$}\"\n",
    "    })\n",
    "    \n",
    "\n",
    "    with open(texfile, 'r') as f:\n",
    "        raw_content = f.read()\n",
    "\n",
    "    processed_content = raw_content\n",
    "    for orig, targ in replace_dict.items():\n",
    "        processed_content = re.sub(orig, targ, processed_content, flags = re.M)\n",
    "\n",
    "    with open(texfile, 'w') as g:\n",
    "        g.write(processed_content)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T09:53:31.636647Z",
     "start_time": "2024-02-09T09:53:30.876751Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "experiment_ids = [f\"{instance_name}_discretevars\" for instance_name in discrete_instances]\n",
    "\n",
    "discrete_df = get_eval_df(experiment_ids, which_results=\"construct\")\n",
    "discrete_pivot = discrete_df.pivot_table(columns=[\"agent\"], index=[\"instance\", \"metric\"])\n",
    "\n",
    "\n",
    "dvfp = deepcopy(discrete_pivot)\n",
    "dvfp.columns = dvfp.columns.droplevel(0)\n",
    "dvfp = pd.DataFrame(dvfp.to_records())\n",
    "\n",
    "dvfp_final = augment_with_cis(dvfp, discrete_df)\n",
    "dvfp_final\n",
    "prepare_and_write_latex(dvfp_final, which_results=\"construct\", file_suffix=\"discrete\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
