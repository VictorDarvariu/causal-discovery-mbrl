{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c49eca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/causal-discovery')\n",
    "\n",
    "from cdrl.agent.mcts.mcts_agent import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "import seaborn as sns\n",
    "\n",
    "from cdrl.io.storage import EvaluationStorage\n",
    "from cdrl.io.file_paths import FilePaths\n",
    "\n",
    "base_suffix = \"timings\"\n",
    "instances = [\"synth10lr\", \"synth15lr\", \"synth20lr\", \"synth25lr\", \"synth30lr\", \"synth35lr\", \"synth40lr\", \"synth45lr\", \"synth50lr\"]\n",
    "\n",
    "exp_ids = [f\"{instance}_{base_suffix}\" for instance in instances]\n",
    "fp_out = FilePaths('/experiment_data', 'aggregate_cdrl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_timings_data = []\n",
    "\n",
    "for exp_id in exp_ids:\n",
    "    fp_in = FilePaths('/experiment_data', exp_id)\n",
    "    storage = EvaluationStorage(fp_in)\n",
    "    emd = storage.get_metrics_data(\"eval\")\n",
    "\n",
    "    for e in emd:\n",
    "        entry = {}\n",
    "        entry['total_duration_s'] = e['duration_construct_s']\n",
    "        entry['per_action_s'] = e['duration_construct_s'] / (len(e['results']['construct']['edges']) * 2)\n",
    "        entry['N'] = int(exp_id.split(\"_\")[0][-4:-2])\n",
    "        entry['agent'] = e['agent']\n",
    "        all_timings_data.append(entry)\n",
    "\n",
    "timings_df = pd.DataFrame(all_timings_data)\n",
    "print(timings_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "d3e9e6ae86680c11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "measurements = [\"per_action_s\"]\n",
    "\n",
    "sns.set(font_scale=3.5)\n",
    "plt.rc('font', family='serif')\n",
    "# mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams[\"lines.linewidth\"] = 8\n",
    "mpl.rcParams[\"lines.markersize\"] = 72\n",
    "\n",
    "\n",
    "palette ={\"uctfull\": \"C0\", \"uctfullnaive\": \"C5\"}\n",
    "legend_i = 0\n",
    "\n",
    "dims = (8.26 * len(measurements) * 1.5, 8.26 * 1.15)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(measurements), figsize=dims, squeeze=False, sharey=False, sharex=False)\n",
    "\n",
    "for i, measurement in enumerate(measurements):\n",
    "    ax = axes[0][i]\n",
    "\n",
    "    sns.lineplot(data=timings_df, x=\"N\", y=measurement, ax=ax, hue=\"agent\", palette=palette)\n",
    "    ax.get_yaxis().get_major_formatter().labelOnlyBase = False\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend_.remove()\n",
    "    ax.set_ylabel(\"Seconds per action\")\n",
    "\n",
    "agent_display_names = {\"uctfull\": \"CD-UCT\",\n",
    "                       \"uctfullnaive\": \"UCT (Naive)\"}\n",
    "display_labels = [agent_display_names[label] for label in labels[1:]]\n",
    "fig.legend(handles[1:], display_labels, loc='upper left', borderaxespad=3.5, fontsize=\"medium\")\n",
    "\n",
    "# fig.suptitle(f\"\", y=0.92, fontsize=64)\n",
    "plt.savefig(fp_out.figures_dir / f\"{base_suffix}_timings.pdf\", bbox_inches=\"tight\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d27ea36ccef9c0ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# timings_df\n",
    "tp = timings_df.pivot_table(columns=[\"agent\"], values=\"per_action_s\", index=\"N\")\n",
    "# tp.columns = tp.columns.droplevel(0)\n",
    "tp[\"speedup\"] = tp[\"uctfullnaive\"] / tp[\"uctfull\"]\n",
    "tp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "189a59f84866b5f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_ids = []\n",
    "\n",
    "# instances = [\"sachs\"] + [f\"syntren{d}\" for d in range(1, 11)]\n",
    "instances = [\"sachs\"] + [f\"syntren1\"]\n",
    "\n",
    "fp_out = FilePaths('/experiment_data', 'aggregate_cdrl')\n",
    "\n",
    "for inst in instances:\n",
    "    experiment_ids.append(f\"{inst}_primary\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c03d44b46fb1a0e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_timings_df(experiment_ids, collapse_syntren=True):\n",
    "    all_timings_data = []\n",
    "\n",
    "    for exp_id in experiment_ids:\n",
    "        fp_in = FilePaths('/experiment_data', exp_id)\n",
    "        storage = EvaluationStorage(fp_in)\n",
    "        emd = storage.get_metrics_data(\"eval\")\n",
    "\n",
    "        for entry in emd:\n",
    "            row_dict = {}\n",
    "\n",
    "            row_dict[\"total_seconds\"] = entry[\"duration_construct_s\"]\n",
    "            row_dict[\"agent\"] = entry[\"agent\"]\n",
    "            if entry[\"agent\"].startswith(\"uct\"):\n",
    "                row_dict[\"agent\"] = \"uct\"\n",
    "\n",
    "            row_dict[\"instance\"] = exp_id.split(\"_\")[0]\n",
    "\n",
    "            if collapse_syntren:\n",
    "                if row_dict[\"instance\"].startswith(\"syntren\"):\n",
    "                    row_dict[\"instance\"] = \"syntren\"\n",
    "\n",
    "            all_timings_data.append(row_dict)\n",
    "\n",
    "    timings_df = pd.DataFrame(all_timings_data)\n",
    "    return timings_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1acdc1cca003a7a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tdf = get_timings_df(experiment_ids)\n",
    "tdf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de8f7f21a93d830"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timings_pivot = tdf.pivot_table(columns=[\"agent\"], index=[\"instance\"])\n",
    "timings_pivot.columns = timings_pivot.columns.droplevel(0)\n",
    "timings_pivot = pd.DataFrame(timings_pivot.to_records())\n",
    "timings_pivot"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d676f5e512f40fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def format_timing(val_s):\n",
    "    if type(val_s) == str:\n",
    "        return val_s\n",
    "\n",
    "    val_ms = val_s * 1000\n",
    "    if np.isnan(float(val_ms)):\n",
    "        return \"---\"\n",
    "\n",
    "    val_seconds = int(val_ms / 1000)\n",
    "    if val_seconds == 0:\n",
    "        timing_string = \"<00:01\"\n",
    "    else:\n",
    "        timing_string = '{:01}:{:02}:{:02}'.format(val_seconds//3600, val_seconds%3600//60, val_seconds%60)\n",
    "    return timing_string\n",
    "\n",
    "timings_pivot = timings_pivot.applymap(format_timing)\n",
    "colorder = [\"instance\", \"uct\", \"rlbic\", \"greedy\", \"randomshooting\", \"random\", \"cam\", \"lingam\", \"notears\", \"pc\", \"ges\"]\n",
    "\n",
    "\n",
    "agent_display_names = {\"uct\": \"CD-UCT\",\n",
    "                       \"rlbic\": \"RL-BIC\",\n",
    "                       \"greedy\": \"Greedy Search\",\n",
    "                       \"random\": \"Uniform Sampling\",\n",
    "                       \"randomshooting\": \"Random Search\",\n",
    "                       \"cam\": \"CAM\",\n",
    "                       \"lingam\": \"LiNGAM\",\n",
    "                       \"notears\": \"NOTEARS\",\n",
    "                       \"ges\": \"GES\",\n",
    "                       \"pc\": \"PC\"}\n",
    "\n",
    "timings_pivot = timings_pivot[colorder]\n",
    "timings_pivot.rename(columns=agent_display_names, inplace=True)\n",
    "\n",
    "texfile =  str(fp_out.figures_dir / f\"timings_final.tex\")\n",
    "fh = open(texfile, 'w')\n",
    "n_startcols = 1\n",
    "colformat = f\"{'c' * n_startcols}|\" + (\"r\"\n",
    "                                       \"\" * (len(colorder) - n_startcols))\n",
    "timings_pivot.to_latex(buf=fh, index=False, column_format=colformat)\n",
    "fh.close()\n",
    "\n",
    "replace_dict = {\n",
    "    r\"instance\" : r\"\",\n",
    "    r\"agg\" : r\"\",\n",
    "    r\"metric\" : r\"\",\n",
    "    r\"reward\": r\"Reward $\\uparrow$\",\n",
    "    r\"tpr\": r\"TPR $\\uparrow$\",\n",
    "    r\"fdr\": r\"FDR $\\downarrow$\",\n",
    "    r\"shd\": r\"SHD $\\downarrow$\",\n",
    "    r\"-100.000\": r\"$\\\\times$\",\n",
    "\n",
    "    r\"sachs\": r\"\\\\textit{Sachs}\",\n",
    "    r\"syntren\": r\"\\\\textit{SynTReN}\",\n",
    "    r\"mrr\": r\"MRR\",\n",
    "\n",
    "    r\"nan±nan\": r\"$\\infty$\",\n",
    "    r\"NaN\": r\"$\\infty$\",\n",
    "    r\"nan\": r\"$\\infty$\",\n",
    "\n",
    "    r\"±(\\d+\\.\\d+)\": r\"\\\\tiny{$\\\\pm\\g<1>$}\",\n",
    "    r\"±---\": r\"\\\\tiny{$\\\\pm0.000$}\"\n",
    "}\n",
    "\n",
    "with open(texfile, 'r') as f:\n",
    "    raw_content = f.read()\n",
    "\n",
    "processed_content = raw_content\n",
    "for orig, targ in replace_dict.items():\n",
    "    processed_content = re.sub(orig, targ, processed_content, flags = re.M)\n",
    "\n",
    "with open(texfile, 'w') as g:\n",
    "    g.write(processed_content)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8d6f3b8da1864"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3b8c3d5bace95d6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-discovery-env",
   "language": "python",
   "name": "cd-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
