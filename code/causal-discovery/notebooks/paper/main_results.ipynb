{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/causal-discovery')\n",
    "\n",
    "from cdrl.agent.mcts.mcts_agent import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cdrl.io.storage import EvaluationStorage\n",
    "from cdrl.io.file_paths import FilePaths\n",
    "\n",
    "experiment_ids = []\n",
    "\n",
    "instances = [\"sachs\"] + [f\"syntren{d}\" for d in range(1, 11)]\n",
    "fp_out = FilePaths('/experiment_data', 'aggregate_cdrl')\n",
    "\n",
    "for inst in instances:\n",
    "    experiment_ids.append(f\"{inst}_primary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics_to_display = {\n",
    "    \"construct\": [\"shd\", \"fdr\", \"tpr\", \"reward\"],\n",
    "    \"prune_cam\": [\"shd\", \"fdr\", \"tpr\"],\n",
    "}\n",
    "\n",
    "def get_eval_df(experiment_ids, which_results=\"construct\", collapse_syntren=True):\n",
    "    all_eval_data = []\n",
    "\n",
    "    for exp_id in experiment_ids:\n",
    "        fp_in = FilePaths('/experiment_data', exp_id)\n",
    "        storage = EvaluationStorage(fp_in)\n",
    "\n",
    "        emd = storage.get_metrics_data(\"eval\")\n",
    "\n",
    "        metrics = metrics_to_display[which_results]\n",
    "\n",
    "        for entry in emd:\n",
    "            for metric in metrics:\n",
    "                row_dict = {}\n",
    "\n",
    "                row_dict[\"metric\"] = metric\n",
    "                row_dict[\"value\"] = entry[\"results\"][which_results][metric]\n",
    "\n",
    "                row_dict[\"agent\"] = entry[\"agent\"]\n",
    "                if entry[\"agent\"].startswith(\"uct\"):\n",
    "                    row_dict[\"agent\"] = \"uct\"\n",
    "\n",
    "                row_dict[\"instance\"] = exp_id.split(\"_\")[0]\n",
    "\n",
    "                if collapse_syntren:\n",
    "                    if row_dict[\"instance\"].startswith(\"syntren\"):\n",
    "                        row_dict[\"instance\"] = \"syntren\"\n",
    "\n",
    "                all_eval_data.append(row_dict)\n",
    "\n",
    "    eval_df = pd.DataFrame(all_eval_data)\n",
    "    return eval_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "construct_df = get_eval_df(experiment_ids, which_results=\"construct\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "construct_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "construct_pivot = construct_df.pivot_table(columns=[\"agent\"], index=[\"instance\", \"metric\"])\n",
    "construct_pivot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prune_df = get_eval_df(experiment_ids, which_results=\"prune_cam\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prune_pivot = prune_df.pivot_table(columns=[\"agent\"], index=[\"instance\", \"metric\"])\n",
    "prune_pivot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_prune_df = get_eval_df(experiment_ids, which_results=\"prune_cam\", collapse_syntren=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "raw_prune_df = raw_prune_df.drop(raw_prune_df[raw_prune_df.instance == \"sachs\"].index)\n",
    "rankings_pivot = raw_prune_df.pivot_table(columns=[\"agent\"], index=[\"instance\", \"metric\"])\n",
    "\n",
    "rankings_pivot.columns = rankings_pivot.columns.droplevel(0)\n",
    "rankings_pivot.drop(columns=[\"notears\"], inplace=True)\n",
    "rankings_pivot = pd.DataFrame(rankings_pivot.to_records())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rankings_data = []\n",
    "for row in rankings_pivot.itertuples():\n",
    "    metric = getattr(row, 'metric')\n",
    "    instance = getattr(row, \"instance\")\n",
    "\n",
    "    algo_perfs = []\n",
    "    all_algos = rankings_pivot.columns.tolist()[2:]\n",
    "\n",
    "    for algo in all_algos:\n",
    "        algo_perfs.append(getattr(row, algo))\n",
    "\n",
    "    perfs_arr = np.array(algo_perfs)\n",
    "    # if metric == \"tpr\":\n",
    "    #     perfs_arr = -perfs_arr\n",
    "\n",
    "    # print(perfs_arr)\n",
    "    perfs_ranked = np.argsort(np.argsort(perfs_arr)) + np.ones(len(algo_perfs))\n",
    "\n",
    "    # print(perfs_ranked)\n",
    "    rrs = np.ones(len(perfs_arr)) / perfs_ranked\n",
    "    # print(rrs)\n",
    "\n",
    "    for i, algo in enumerate(all_algos):\n",
    "        rankings_data.append({\"metric\": metric,\n",
    "                              \"agent\": algo,\n",
    "                              \"rr\": rrs[i]})\n",
    "\n",
    "rdf = pd.DataFrame(rankings_data)\n",
    "# rdf = rdf.reset_index(drop=True)\n",
    "# rdf\n",
    "rdfp = rdf.pivot_table(columns=[\"agent\"], index=[\"metric\"])\n",
    "rdfp.columns = rdfp.columns.droplevel(0)\n",
    "# rdfp[\"agg\"] = [\"mrr\"] * len(rdfp)\n",
    "rdfp[\"instance\"] = [\"syntren\"] * len(rdfp)\n",
    "rdfp = pd.DataFrame(rdfp.to_records())\n",
    "\n",
    "pp_copy = deepcopy(prune_pivot)\n",
    "pp_copy.columns = pp_copy.columns.droplevel(0)\n",
    "mdfp = pd.DataFrame(pp_copy.to_records())\n",
    "# mdfp[\"agg\"] = [\"mean\"] * len(pp_copy)\n",
    "\n",
    "# joint_prune_df = pd.concat([rdfp, mdfp])\n",
    "# joint_prune_df\n",
    "\n",
    "cdfp = deepcopy(construct_pivot)\n",
    "cdfp.columns = cdfp.columns.droplevel(0)\n",
    "cdfp = pd.DataFrame(cdfp.to_records())\n",
    "\n",
    "for excluded_agent in [\"cam\", \"lingam\", \"notears\", \"ges\", \"pc\"]:\n",
    "    cdfp[excluded_agent] = [-999.] * len(cdfp)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "def compute_ci(data, confidence=0.95):\n",
    "    if len(data) == 1:\n",
    "        return 0.\n",
    "\n",
    "    a = np.array(data)\n",
    "    n = len(a)\n",
    "    se = sp.stats.sem(a)\n",
    "    h = se * sp.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h\n",
    "\n",
    "def augment_with_cis(results_pivot, orig_df):\n",
    "    pivot_cp = deepcopy(results_pivot)\n",
    "\n",
    "    all_algos = results_pivot.columns.tolist()[2:]\n",
    "    all_algos = [a for a in all_algos if a not in [\"greedy\", \"cam\", \"notears\", \"lingam\", \"ges\", \"pc\"]]\n",
    "\n",
    "    for algo in all_algos:\n",
    "        algo_cis = []\n",
    "\n",
    "        for row in results_pivot.itertuples():\n",
    "            metric = getattr(row, 'metric')\n",
    "            instance = getattr(row, \"instance\")\n",
    "\n",
    "            # print(algo, metric, instance)\n",
    "            relevant_entries = orig_df[(orig_df[\"metric\"] == metric) &\n",
    "                                       (orig_df['instance'] == instance) &\n",
    "                                       (orig_df['agent'] == algo)]\n",
    "            metric_values = relevant_entries[\"value\"].tolist()\n",
    "            ci = compute_ci(metric_values)\n",
    "            # print(metric_values, ci)\n",
    "            algo_cis.append(ci)\n",
    "\n",
    "        pivot_cp[f\"{algo}_ci\"] = algo_cis\n",
    "\n",
    "    for algo in all_algos:\n",
    "        colname_ci = f\"{algo}_ci\"\n",
    "        pivot_cp[algo] = pivot_cp.agg(lambda x: f\"{x[algo]:.3f}±{x[colname_ci]:.3f}\", axis=1)\n",
    "        pivot_cp.drop(columns=[colname_ci], inplace=True)\n",
    "\n",
    "    return pivot_cp\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cdfp_final = augment_with_cis(cdfp, construct_df)\n",
    "cdfp_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mdfp\n",
    "mdfp_final = augment_with_cis(mdfp, prune_df)\n",
    "mdfp_final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def prepare_and_write_latex(df, which_results=\"construct\", file_suffix=\"\"):\n",
    "    if which_results == \"joint\":\n",
    "        colorder = [\"phase\", \"instance\", \"metric\", \"uct\", \"rlbic\", \"greedy\", \"randomshooting\", \"random\", \"cam\", \"lingam\", \"notears\", \"ges\", \"pc\"]\n",
    "    elif which_results == \"prune_cam\":\n",
    "        colorder = [\"instance\", \"metric\", \"uct\", \"rlbic\", \"greedy\", \"randomshooting\", \"random\", \"cam\", \"lingam\", \"notears\", \"ges\", \"pc\"]\n",
    "    elif file_suffix == \"\":\n",
    "        colorder = [\"instance\", \"metric\", \"uct\", \"rlbic\", \"greedy\", \"randomshooting\", \"random\",  \"cam\", \"lingam\", \"notears\", \"ges\", \"pc\"]\n",
    "    else:\n",
    "        colorder = [\"metric\", \"uct\", \"rlbic\", \"greedy\", \"randomshooting\", \"random\", \"cam\", \"lingam\", \"notears\", \"ges\", \"pc\"]\n",
    "\n",
    "    agent_display_names = {\"uct\": \"CD-UCT\",\n",
    "                           \"rlbic\": \"RL-BIC\",\n",
    "                           \"greedy\": \"Greedy Search\",\n",
    "                           \"random\": \"Uniform Sampling\",\n",
    "                           \"randomshooting\": \"Random Search\",\n",
    "                           \"cam\": \"CAM\",\n",
    "                           \"lingam\": \"LiNGAM\",\n",
    "                           \"notears\": \"NOTEARS\",\n",
    "                           \"ges\": \"GES\",\n",
    "                           \"pc\": \"PC\"\n",
    "                           }\n",
    "\n",
    "    df = df[colorder]\n",
    "    df['metric'] = pd.Categorical(df['metric'],categories=['reward', 'tpr','fdr','shd'], ordered=True)\n",
    "\n",
    "    if which_results == \"joint\":\n",
    "        df = df.sort_values(by=[\"phase\", \"instance\", \"metric\"])\n",
    "    elif file_suffix == \"\":\n",
    "        df = df.sort_values(by=[\"instance\", \"metric\"])\n",
    "    else:\n",
    "        df = df.sort_values(by=[\"metric\"])\n",
    "\n",
    "    if which_results == \"prune_cam\":\n",
    "        df.loc[ df[\"instance\"] == \"syntren\", [\"notears\"]] = -100\n",
    "    df.rename(columns=agent_display_names, inplace=True)\n",
    "\n",
    "    texfile =  str(fp_out.figures_dir / f\"{which_results}_final{'_' + file_suffix if file_suffix != '' else ''}.tex\")\n",
    "    fh = open(texfile, 'w')\n",
    "\n",
    "    n_startcols = 3 if which_results == \"joint\" else (2 if file_suffix == \"\" else 1)\n",
    "\n",
    "    colformat = f\"{'c' * n_startcols}|\" + (\"r\" * (len(colorder) - n_startcols))\n",
    "    df.to_latex(buf=fh, float_format=\"{:0.3f}\".format, index=False, column_format=colformat)\n",
    "    fh.close()\n",
    "\n",
    "    replace_dict = {\n",
    "        r\"instance\" : r\"\",\n",
    "        r\"agg\" : r\"\",\n",
    "        r\"metric\" : r\"\",\n",
    "        r\"phase\": r\"Phase\",\n",
    "        r\"construct\": r\"\\\\textbf{Construct}\",\n",
    "        r\"prune\": r\"\\\\textbf{Prune}\",\n",
    "\n",
    "        r\"reward\": r\"Reward $\\uparrow$\",\n",
    "        r\"tpr\": r\"TPR $\\uparrow$\",\n",
    "        r\"fdr\": r\"FDR $\\downarrow$\",\n",
    "        r\"shd\": r\"SHD $\\downarrow$\",\n",
    "        r\"-100.000\": r\"$\\\\times$\",\n",
    "        r\"-999.000\": r\"---\",\n",
    "\n",
    "        r\"sachs\": r\"\\\\textit{Sachs}\",\n",
    "        r\"syntren\": r\"\\\\textit{SynTReN}\",\n",
    "        r\"mrr\": r\"MRR\",\n",
    "\n",
    "        r\"nan±nan\": r\"$\\infty$\",\n",
    "        r\"NaN\": r\"$\\infty$\",\n",
    "        r\"nan\": r\"$\\infty$\",\n",
    "\n",
    "        r\"±(\\d+\\.\\d+)\": r\"\\\\tiny{$\\\\pm\\g<1>$}\",\n",
    "        r\"±---\": r\"\\\\tiny{$\\\\pm0.000$}\"\n",
    "    }\n",
    "\n",
    "    with open(texfile, 'r') as f:\n",
    "        raw_content = f.read()\n",
    "\n",
    "    processed_content = raw_content\n",
    "    for orig, targ in replace_dict.items():\n",
    "        processed_content = re.sub(orig, targ, processed_content, flags = re.M)\n",
    "\n",
    "    with open(texfile, 'w') as g:\n",
    "        g.write(processed_content)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "joint_cdfp = deepcopy(cdfp_final)\n",
    "joint_cdfp[\"phase\"] = [\"construct\"] * len(joint_cdfp)\n",
    "\n",
    "joint_mdfp = deepcopy(mdfp_final)\n",
    "joint_mdfp[\"phase\"] = [\"prune\"] * len(joint_mdfp)\n",
    "\n",
    "joint_df = pd.concat([joint_cdfp, joint_mdfp])\n",
    "prepare_and_write_latex(joint_df, which_results=\"joint\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_ids = [\"synth50qr_scaleup\"]\n",
    "\n",
    "scaleup_df = get_eval_df(experiment_ids, which_results=\"construct\")\n",
    "\n",
    "scaleup_pivot = scaleup_df.pivot_table(columns=[\"agent\"], index=[\"instance\", \"metric\"])\n",
    "\n",
    "\n",
    "sdfp = deepcopy(scaleup_pivot)\n",
    "sdfp.columns = sdfp.columns.droplevel(0)\n",
    "sdfp = pd.DataFrame(sdfp.to_records())\n",
    "\n",
    "sdfp_final = augment_with_cis(sdfp, scaleup_df)\n",
    "sdfp_final[\"rlbic\"] = [float(\"nan\")] * len(sdfp_final)\n",
    "\n",
    "prepare_and_write_latex(sdfp_final, which_results=\"construct\", file_suffix=\"scaleup\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sdfp_final"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
